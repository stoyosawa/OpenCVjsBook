<!DOCTYPE html>
<html lang="ja-JP">
<head>
  <meta charset="UTF-8">
  <link rel=stylesheet type="text/css" href="style.css">
  <script async src="libs/opencv.js" type="text/javascript"></script>
</head>
<body>

<h1>カメラ映像を鏡像反転する</h1>

<div>
  <video id="videoTag" controls></video>
  <canvas id="canvasTag" class="placeholder"></canvas>
</div>

<script>
  let videoElem = document.getElementById('videoTag');
  let buttonElem = document.getElementById('buttonTag');
  let src, dst;
  let readyFlag = 0;

  let constraints = {
    audio: false,
    video: { width: 360, height: 270 }
  };

  navigator.mediaDevices.getUserMedia(constraints)
  .then(mediaStream => {
    videoElem.srcObject = mediaStream;
    videoElem.play();
  });

  function perFrame() {
    let cap = new cv.VideoCapture(videoElem);
    let src = new cv.Mat(videoElem.height, videoElem.width, cv.CV_8UC4);
    cap.read(src);
    cv.flip(src, src, 1);
    cv.imshow('canvasTag', src);

    src.delete();
    videoElem.requestVideoFrameCallback(perFrame);
  }

  function videoStop() {
    console.log('video stopped');
    videoElem.pause();
    let tracks = videoElem.srcObject.getTracks();
    tracks[0].stop();
    videoElem.srcObject = undefined;
    videoElem.removeEventListener('pause', videoStop);
    readyFlag = 0;
  }

  function init() {
    if (readyFlag !== 3)
      return;
    videoElem.addEventListener('pause', videoStop);
    perFrame();
  }

  function videoReady() {
    console.log('video ready');
    videoElem.width = videoElem.videoWidth;
    videoElem.height = videoElem.videoHeight;
    readyFlag |= 1;
    init();
  }

  function opencvReady() {
    console.log('openv ready');
    readyFlag |= 2;
    init();
  }

  videoElem.addEventListener('loadeddata', videoReady)
  var Module = {
    onRuntimeInitialized: opencvReady
  }
</script>

</body>
</html>