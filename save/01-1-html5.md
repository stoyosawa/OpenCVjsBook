## 第1章 HTML5の画像・ビデオ操作

オリジナルのC/C++やPython版のOpenCVには、ユーザインタフェース機能が用意されています。機能はさほど豊富ではありませんが、画像表示やマウス操作などの簡単なユーザ操作なら、OpenCVだけで記述ができます。

これに対し、JavaScript版のOpenCV.jsにはユーザインタフェース機能がありません。HTML5にすでに用意されているからです。画像の取り込みや表示には、いつもの`<img>`、`<video>`、`<canvas>`といったHTML要素（タグ）を用います。カメラからの読み込みも同様で、ブラウザ（ユーザエージェント）を管理する`Navigator`オブジェクトから操作します。キーボードやマウスなどのユーザ操作は、`<input>`などの要素や`mousedown`などの`Event`オブジェクトで管理します。

本章では、これらのHTML5ユーザインタフェースを、本書の主題であるOpenCVスクリプティングに必要な範囲で説明します。HTML5のメディア機能に問題のない読者は、第2章に進んでください。

CSSも利用できますが、OpenCVとは直接的には関係しません。本書のサンプルコードでは、日本語文字を画像上に提示するために透明なキャンバスを画像の上にオーバーレイする（[1.7節](01-2-html5.md#17-文字列要素の重畳 "INTERNAL")）、CSS画像フィルタを例題に用いる（[1.8節](01-2-html5.md#18-ユーザ操作を制御する "INTERNAL")）、空白なキャンバスが見えるように枠線を加えるといった見栄えの調整に使うだけです。使用するCSSファイル（`style.css`）は[付録](TBA "INTERNAL")に掲載してあります。



### 1.1 画像を表示する

#### 画像処理の流れ

WebページでのOpenCVの画像処理の流れを次図から示します。

<!-- 544 x 277 -->
<img src="Images/Ch01/html-image-processing.png" height="150">

①画像は`<img src>`で読み込みます。ファイルやURLを選択させるのなら、`<input>`から取得し、スクリプトで`<img>`のDOMオブジェクト（`HTMLImageElement`）に貼り付けます（[1.8節](01-2-html5.md#18-ユーザ操作を制御する "INTERNAL")で説明します）。ビデオならばここは`<video>`になります（[1.2節](#12-ビデオを表示する "INTERNAL")）。画像処理はビデオであっても静止画（フレーム）を対象とするのが基本なので、処理の流れはさほど変わりません（ビデオをフレームに分解する方法は[1.6節](01-2-html5.md#16-ビデオをフレーム単位で処理する "INTERNAL")）。カメラも同様です（[1.5節](#15-カメラを操作する "INTERNAL")）。

②得られた画像は`<script>`内のOpenCVスクリプトで処理します。画像処理は[第2章](./02-opencv.js "INTERNAL")以降で説明します。

③処理が完了したら、結果の画像を`<canvas>`に貼り付けます。

本節では①の読み込みと③のキャンバスへの貼り付けの方法を、HTML要素とそれに対応するDOMオブジェクトを確認しながら説明していきます。

#### 画像をキャンバスに貼り付ける

まずは、入力画像を無処理のままキャンバスに貼り付けるという基本動作のスクリプトを取り上げます。スクリプトを取り上げるに先立ち、次に動作画面を示します。

<img src="Images/Ch01/html-image-1.png">

左が読み込んだ画像を表示する`<img>`で、右がそのコピーを貼り付けた`<canvas>`です。キャンバスにはその領域が目視できるように点線の枠を付けてありますが、これはCSSによる見栄えの調整なだけで、本質とは無関係です（枠線のスタイルは`outline: 2px gray dotted;`です）。

コードは次の通りです。ファイル名は`html-image1.html`です。

<!-- 動作確認（✔️❌）： Local/Normal Firefox✔️ Chrome✔️ Edge✔️, Local/CORS Firefox Chrome Edge, HTTP Firefox Chrome Edge -->
```html
[File] html-image1.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6  </head>
  7  <body>
  8
  9  <h1>画像を読み込み、キャンバスに表示</h1>
 10
 11  <div>
 12    <img id="imageTag" width="320" src="samples/sheep.jpg"/>
 13    <canvas id="canvasTag" class="placeholder"></canvas>
 14  </div>
 15
 16  <script>
 17    let imgElem = document.getElementById('imageTag');
 18    let canvasElem = document.getElementById('canvasTag');
 19    let ctx = canvasElem.getContext('2d');
 20
 21    function showImage() {
 22      ['width', 'height', 'naturalWidth', 'naturalHeight'].forEach(function(d) {
 23        console.log(`img.${d}: ${imgElem[d]}, canvas.${d}: ${canvasElem[d]}`);
 24      });
 25      canvasElem.width = imgElem.width;
 26      canvasElem.height = imgElem.height;
 27      ctx.drawImage(imgElem, 0, 0, imgElem.width, imgElem.height);
 28    }
 29
 30    imgElem.addEventListener('load', showImage);
 31  </script>
 32
 33  </body>
 34  </html>
```

#### img要素

HTMLページに画像ファイルを取り込むには`<img>`要素を使います（12行目）。ファイルのURLは`src`属性から指定します。

```html
12    <img id="imageTag" width="320" src="samples/sheep.jpg"/>
```

`src`以外の属性は仕様上オプションです。ここでは`width`属性に320ピクセルを指定していますが、動作確認時に邪魔にならない程度に縮小表示したいからです。`height`は未指定ですが、高さは元画像のアスペクト比に準じて自動的に調整されます。ここでの用例では、元画像のサイズが1280×885なので、高さは1/4の221ピクセルに縮小されます。

スクリプティングで必須なのは、`<img>`要素を特定する`id`属性です。ここではimageTagです。

画像が完全に読み込まれるまでは、処理は始められません。そこで、画像処理を担当するメソッドの`showImage()`（21～28行目）を、読み込み完了イベント`load`の発生を契機に起動させます。`<img>`要素に対応する`HTMLImageElement`オブジェクトにイベントを登録するには、`addEventListener()`メソッドを用います（30行目）。

```javascript
 17    let imgElem = document.getElementById('imageTag');
 ︙
 30    imgElem.addEventListener('load', showImage);
``` 

#### canvas要素

`<img>`で取り込んだ画像のコピーを貼り付ける領域（キャンバス）は、`<canvas>`要素から用意します（13行目）。`<img>`要素同様、`id`属性にセットした識別子から対応するDOM（`HTMLCanvasElement`オブジェクト）も用意します（18行目）。

```html
13    <canvas id="canvasTag" class="placeholder"></canvas>
︙
18    let canvasElem = document.getElementById('canvasTag');
```

`width`や`height`の属性を指定していないので、ページ上ではデフォルトの300×150のスペースが確保されます。次の画面は画像がコピーされる前の初期状態です。キャンバスサイズがデフォルトのままなのが枠線からわかります。

<img src="Images/Ch01/html-image-2.png">

#### 描画コンテクスト
<!-- Wikipedia は「コンテキスト」のほうが多いと言っているが、あたしは自然には「コンテクスト」と打つので、そちらを採用。無理に「キ」にすると、揺れが多すぎる。-->

キャンバスに対する操作は、キャンバスの描画コンテクストを介して行います。「コンテクスト」（文脈）ではやや意味不明瞭ですが、仮想的なキャンバスと考えてください。この仮想的なキャンバスに対して画像貼り付けやグラフィック描画を行うと、`<canvas>`というビューファインダーからそれらが見えるようになるという塩梅です。

描画コンテクストは、`HTMLCanvasElement`の`getContect()`メソッドから取得します（19行目）。

```javascript
 19      let ctx = canvas.getContext('2d');
```

引数には5つほど選択肢がありますが、2次元での描画では2dで決め打ちです。戻り値は`CanvasRenderingContext2D`というオブジェクトです。

#### 画像のコピー

21～28行目で定義した`showImage()`メソッドは、`HTMLImageElement`（`<img>`）の画像を
描画コンテクストにコピーします。コピーするメソッドは`CanvasRenderingContext2D`の`drawImage()`メソッドです（27行目）。

```javascript
 27      ctx.drawImage(imgElem, 0, 0, imgElem.width, imgElem.height);
```

第1引数には、コピー元の画像オブジェクトを指定します。

第2引数と第3引数には、その画像を貼り付けるキャンバス内での(x, y)座標を指定します。ここでは(0, 0)を指定しているので、キャンバスと画像の左上の位置は一致します。

第4引数と第5引数には、貼り付けるサイズを指定します。ここでは、ページ上での`<img>`と同じサイズ（`width`属性で指定した320×221）を用いたいので、`imgElem.width`と`imgElem.height`を指定しています。

#### いろいろなサイズ

画像やキャンバスにはサイズを示す複数のプロパティがあります。22～24行目は、参考までにこれをコンソールに印字しています。

```javascript
 22      ['width', 'height', 'naturalWidth', 'naturalHeight'].forEach(function(d) {
 23        console.log(`img.${d}: ${imgElem[d]}, canvas.${d}: ${canvasElem[d]}`);
 24      });
```

`width`、`height`はHTML要素の属性で指定された、ページ上に表示されるサイズを示します。`natural`が先付けされたものはファイルにあるもともとのサイズです。`<canvas>`にはもともとのサイズがないので、これらプロパティは存在しません（アクセスすると`undefined`になる）。出力結果を次に示します。

```
img.width: 320, canvas.width: 300
img.height: 221, canvas.height: 150
img.naturalWidth: 1280, canvas.naturalWidth: undefined
img.naturalHeight: 885, canvas.naturalHeight: undefined
```

キャンバスではサイズの属性を設定してなかったので、値はデフォルトの300×150です。このままだと、`<img>`上では320×221だった画像が左上を揃えたうえで300×150で切り取られるので、下部の71ピクセルと右の20ピクセルが、次の画面のようにクリッピングされます。

<img src="Images/Ch01/html-image-3.png">

`<img>`と同じものを`<canvas>`に貼り付けるには、キャンバスのサイズを揃えます（25～26行目）。

```JavaScript
 25      canvasElem.width = imgElem.width;
 26      canvasElem.height = imgElem.height;
```

13行目で次のように`width="320" height="221"`と記述してもかまいません。

```html
 13    <canvas id="canvasTag" width="320" height="221" class="placeholder"></canvas>
```

横縦両方指定しているところに注意してください。`<img>`と異なり、未指定側は自動調節されないので、値はデフォルトのままです。`width="320"`単体での指定はつまり320×150となるので、下部分が次の画面のようにクリッピングされます。前の300×150の画面とは微妙にしか違いませんが、横幅が長いぶん、右端の稜線や湖手前の樹が20ピクセルぶん多く含まれます。

<img src="Images/Ch01/html-image-4.png">

`<canvas>`の属性値をじか書きするのはわかりやすいかもしれませんが、画像を変えるたびに、アスペクト比をあわせて高さを計算しなければなりません。スクリプトで処理したほうが面倒がなくてよいでしょう。

#### 画像の部分コピー

27行目で用いた描画コンテクストの`CanvasRenderingContext2D.drawImage()`メソッドは、引数を調節するだけで、元画像の部分領域を縮小拡大しながらコピーすることもできます。

例を次に示します。

<!-- 枠なし版あり -->
<img src="Images/Ch01/html-image-5.png">

左が`<img>`です。おおもとの画像サイズは1280×885ですが、`<img widht="320">`と属性からサイズ指定しているので、320×221と1/4に縮小表示されます。中央の`<canvas>`には、「おおもとの」画像から、座標(65, 549)を左上の頂点とした415×315の矩形領域を切り取って貼り付けています。元画像で白枠でくくった部分です。右はこれを縦横ともに半分に縮小しています。

ここでは「おおもと」とは`<img>`の`width`あるいは`height`でリサイズされる前の画像です。プロパティでいえば`narutalWidth`×`naruralHeight`です。`drawImage()`の第1引数はこのおおもとの画像を参照します。

もう一度、`html-image1.html`の27行目を確認します。5つの引数が指定されています。

```javascript
 27      ctx.drawImage(imgElem, 0, 0, imgElem.width, imgElem.height);
```

第1引数の`imgElem`のサイズはロードしたファイルのオリジナルのまま、つまり1280×885です。第3、4引数には`HTMLImageElement`の`width`と`height`プロパティが指定されているので、キャバス上の画像のサイズは`<img>`と同じ320×221です。これは縮小表示の指示です。

`drawImage()`メソッドの8引数バージョンでは、コピー元の部分矩形領域も指示できます。構文は次の通りです。

```
drawImage(
  image,                       // 入力画像
  sx, sy, sWidth, sHeight,     // 入力上での左上の頂点の座標とそのサイズ
  dx, dy, dWidth, dHeight      // キャンバスでの左上の頂点の座標とそのサイズ
)
```

27行目の5引数の記法は、3行目の入力側（source）の情報をデフォルトとして省略したものです。デフォルトでは左上の頂点座標(`sx`, `sy`)は(0, 0)に、サイズの`sWidth`×`sHeihgt`は`image.naruralWidth`×`image.naturalHeight`となります。

では、先に示した例を出力するコードを次に示します（ファイル名は`html-image2.html`）。

```html
[File] html-image2.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6  </head>
  7  <body>
  8
  9  <h1>部分画像を読み込み、キャンバスに原寸と1/2で表示</h1>
 10
 11  <div>
 12    <img id="imageTag" width="320" src="samples/sheep.jpg"/>
 13    <canvas id="canvasTag1" class="placeholder"></canvas>
 14    <canvas id="canvasTag2" class="placeholder"></canvas>
 15  </div>
 16
 17  <script>
 18    let imgElem = document.getElementById('imageTag');
 19    let canvasElem1 = document.getElementById('canvasTag1');
 20    let ctx1 = canvasElem1.getContext('2d');
 21    let canvasElem2 = document.getElementById('canvasTag2');
 22    let ctx2 = canvasElem2.getContext('2d');
 23
 24    let [x_img, y_img, w_img, h_img] = [65, 549, 415, 315];
 25
 26    function showImage() {
 27      canvasElem1.width = w_img;
 28      canvasElem1.height = h_img;
 29      ctx1.drawImage(imgElem,
 30        x_img, y_img, w_img, h_img,
 31        0, 0, w_img, h_img
 32      );
 33
 34      canvasElem2.width = Math.floor(w_img * 0.5);
 35      canvasElem2.height = Math.floor(h_img * 0.5);
 36      ctx2.drawImage(imgElem,
 37        x_img, y_img, w_img, h_img,
 38        0, 0, canvasElem2.width, canvasElem2.height
 39      );
 40    }
 41
 42    imgElem.addEventListener('load', showImage);
 43  </script>
 44
 45  </body>
 46  </html>
```

中央と右のキャンバス2つとそれらのコンテクストを用意し、それぞれ描いています。画面で白枠で示した切り出し領域は24行目で定義してありますが、これはもともとの画像（1280×885）のなかの座標系のものです。

```javascript
 24    let [x_img, y_img, w_img, h_img] = [65, 549, 415, 315];
```

中央のキャンバス1（`canvasElem1`と`ctx1`）へのリサイズなしの描画は27～31行目です。

```javascript
 27      canvasElem1.width = w_img;
 28      canvasElem1.height = h_img;
 29      ctx1.drawImage(imgElem,
 30        x_img, y_img, w_img, h_img,
 31        0, 0, w_img, h_img
 32      );
```

キャンバス1には24行目のサイズをそのまま用いているので（27、28行目）、これは原寸大です。30行目の画像（入力）側の座標は、もともとの画像の座標系なので24行目そのままです。31行目はこれをそのままキャンバス1に張り付けています（32行目）。

右側のキャンバス2（`canvasElem2`と`ctx2`）は、24行目の領域の半分のサイズです（34、35行目）。もともとの画像から切り抜く領域はキャンバス1と同じですが（30行目と37行目が同じ）、半分のサイズに縮小してコピーいます（38行目）。

```javascript
 34      canvasElem2.width = Math.floor(w_img * 0.5);
 35      canvasElem2.height = Math.floor(h_img * 0.5);
 36      ctx2.drawImage(imgElem,
 37        x_img, y_img, w_img, h_img,
 38        0, 0, canvasElem2.width, canvasElem2.height
 39      );
```



### 1.2 ビデオを表示する

#### video要素

ビデオを表示するには`<video>`要素を用います。本節ではこの`<video>`のベーシックな用法と、ボタンクリックでフレームをキャプチャする方法を示します。

まずはベーシックな用法です。動作状況を次の画面に示します。

<img src="Images/Ch01/html-video-1.png">

コードは次の通りです（ファイル名は`html-video1.html`）。

```html
[File] html-video1.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6  </head>
  7  <body>
  8
  9  <h1>ビデオ表示</h1>
 10
 11  <div>
 12    <video id="videoTag" width="480" controls src="samples/cat.mp4"
 13      type="video/mp4">
 14    </video>
 15  </div>
 16
 17  <script>
 18    let startTime = Date.now();
 19    let videoElem = document.getElementById('videoTag');
 20
 21    function showMetadata(evt) {
 22      console.log(`Video properties:
 23        Size offset:    ${videoElem.offsetWidth} x ${videoElem.offsetHeight}
 24        Size (element): ${videoElem.width} x ${videoElem.height}
 25        Size video:     ${videoElem.videoWidth} x ${videoElem.videoHeight}
 26        Duration:       ${videoElem.duration}s
 27        CurrentTime:    ${videoElem.currentTime}s
 28        Volume:         ${videoElem.volume} [0, 1]
 29        Play rate:      ${videoElem.playbackRate}
 30        Loop:           ${videoElem.loop}`
 31      );
 32    }
 33
 34    let events = [
 35      'ended', 'error', 'loadeddata', 'loadedmetadata', 'loadstart', 'pause', 'play',
 36      'playing', 'seeked', 'seeking', 'suspend', 'volumechange'
 37    ];
 38    events.forEach(function(evt) {
 39      videoElem.addEventListener(evt, function() {
 40        let delta = (Date.now() - startTime).toLocaleString();
 41        console.log(`${delta}. event: ${evt}`);
 42      });
 43    });
 44
 45    videoElem.addEventListener('loadedmetadata', showMetadata);
 46  </script>
 47
 48  </body>
 49  </html>
```

ビデオを流すだけなら`<video>`だけでよいのですが、ビデオのプロパティやイベントを説明するための参考情報のために長くなっています。

#### video要素の属性

12～14行目の`<video>`で設定する属性で必須なものは、この要素を識別する`id`と`src`だけです。その他はオプションです。

```html
 12    <video id="videoTag" width="480" controls src="samples/cat.mp4"
 13      type="video/mp4">
 14    </video> 
```

`src`のメディアタイプを示す`type`属性は、複数のビデオファイルから選択できるようにしているときは、あったほうがよいでしょう。ブラウザが、表示可能なものをこの情報から判断してピックアップできるからです。ビデオファイルを複数指定するときは`<video>`の子要素である`<source>`を指定します。次にサンプルを示します。

```html
<video id="videoTag">
  <source src="samples/cat.mov" type="video/mov">
  <source src="samples/cat.mp4" type="video/mp4">
</video>
```

`type`がなければ、最初に記述されたMOVファイルがダウンロードされます。しかし、このフォーマットはSafari以外ではたいていサポートされていません。なので、これは廃棄され、次がダウンロードされます。

ビデオ操作のための属性のなかでもよく用いるものを次の表に示します。

属性 | デフォルト値 | 意味 
---|---|---
`autoplay` | `false` | この属性が記述されていると、ビデオが自動再生される。
`controls` | `false` | この属性が記述されていると、再生ボタンなどの操作パネルが表示される。
`loop` | `false` | この属性が記述されていると、末尾まで再生するとまた先頭に戻る。デフォルトでは1回だけ再生。
`muted` | `false` | この属性が記述されていると、オーディオがオフ（ミュート）される。
`poster` | なし | URLを指定すると、ビデオの先頭フレームがダウンロードされるまで、その画像が表示される（[1.5節](#15-カメラを操作する "INTERNAL")で取り上げます）。

`controls`を加えると、再生、一時停止、先送りなどの操作をするパネルが表示されます。外観はブラウザによって異なります。スクリプトで再生を完全にコントロールするのでなければ、たいていはこの属性を加えます。もっとも、初期状態で表示されなくても、たいていは左マウスクリックで引き出されるので、操作に困ることはありません。

起動時に自動再生をする`autoplay`とサウンドをミュートにする`muted`はたいていペアで指定します。ページアクセスと同時に大音量でビデオが始めると、職場や学校で恥ずかしい思いをするからです。

#### HTMLVideoElementのイベント

`HTMLVideoElement`には一般的なものに加えて、たくさんのイベントが用意されています。どのタイミングでこれらが発生するかを確認できるよう、コードの34～43行目で代表的なものを12点登録しています。発生時点がわかりやすいよう、イベント名とともにスクリプト起動時（18行目）からの時間差（40行目）もコンソールに表示します。

```javascript
 18    let startTime = Date.now();
 ︙
 34    let events = [
 35      'ended', 'error', 'loadeddata', 'loadedmetadata', 'loadstart', 'pause', 'play',
 36      'seeked', 'seeking', 'suspend', 'volumechange'
 37    ];
 38    events.forEach(function(evt) {
 39      videoElem.addEventListener(evt, function() {
 40        let delta = (Date.now() - startTime).toLocaleString();
 41        console.log(`${delta}. event: ${evt}`);
 42      });
 43    });
```

これらイベントの意味を次の表に示します。

イベント | 発火タイミング
---|---
`ended` | ビデオが最後まで行ったとき。ただし、ループ時には発火しない。
`error` | ネットワーク障害など、読み込みに失敗したとき。
`loadeddata` | 最初のフレームが読み込まれたとき。以降のフレームでは出てこない。
`loadedmetadata` | フレームサイズなどビデオのメタデータが読み込まれたとき。`loadeddata`よりも先。
`pause` | （操作パネルなどから）一時停止されたとき。
`play` | 再生開始時。
`seeked` | （操作パネルなどから）先送りや後戻りの操作が完了したとき。
`seeking` | （操作パネルなどから）先送りや後戻りの操作が開始したとき。`seeked`よりも先。
`suspend` | データ読み込みが中断されたとき。たいていは`pause`の前。
`volumechange` | 音量が変更されたとき。

大半はオーディオと共通しているので、これらイベントは`HTMLVideElement`の親クラスの`HTMLMediaElement`に属しています。

コンソール出力を、21～31行目が出力するメタデータは省いて次に示します。左の数値は、スクリプト開始時（8行目）からのミリ秒を示します。右のコメントは筆者の操作です。

```
2. event: loadedmetadata      // ページアクセス
5. event: loadeddata
2,210. event: play            // 操作パネルから▷（再生）をクリック
2,513. event: suspend         // 操作パネルから⏸︎（一時停止）をクリック
4,291. event: pause
5,991. event: seeking         // 操作パネルから●（再生位置）をドラッグして再生位置を変更
6,023. event: seeked
︙                            // seeking/seeked が繰り返される
6,292. event: seeking
6,294. event: seeked
8,363. event: play            // 操作パネルから▷（再生）をクリック
9,804. event: pause           // 操作パネルから⏸︎（一時停止）をクリック
```

ビデオのサイズや時間長などの情報を得るのは`loadedmetadata`よりあとでなければなりません。コピーなどフレーム操作は`loadeddata`後です。両者はほぼ同時ですが、それでも（ここでは）3ミリ秒の間隔が空いているところに注意してください。

再生位置変更の`seeking`と`seeked`は、操作しているあいだは連続して出てくるところもポイントです。

#### HTMLVideoElementのプロパティ

コードの21～32行目に定義した`showMetadata()`メソッドは、ビデオのメタデータをコンソールに表示します。このメソッドは、45行目から`loadedmetadata`イベントを契機に起動するよう登録してあります。

```javascript
 21    function showMetadata(evt) {
 22      console.log(`Video properties:
 23        Size offset:    ${videoElem.offsetWidth} x ${videoElem.offsetHeight}
 24        Size (element): ${videoElem.width} x ${videoElem.height}
 25        Size video:     ${videoElem.videoWidth} x ${videoElem.videoHeight}
 26        Duration:       ${videoElem.duration}s
 27        CurrentTime:    ${videoElem.currentTime}s
 28        Volume:         ${videoElem.volume} [0, 1]
 29        Play rate:      ${videoElem.playbackRate}
 30        Loop:           ${videoElem.loop}`
 31      );
 32    }
 ︙
 45    videoElem.addEventListener('loadedmetadata', showMetadata);
```

出力を、直前のイベントも含めて次に示します。後付けのコメントにプロパティ名を示しました。

```
2. event: loadedmetadata           // loadmetada以降に取得可
Video properties:
      Size offset:    480 x 270    // offsetWidth、offsetHeight
      Size (element): 480 x 0      // width、height
      Size video:     640 x 360    // videoWidth、videoHeight
      Duration:       9.217542s    // duration
      CurrentTime:    0s           // currentTime
      Volume:         1 [0, 1]     // volume
      Play rate:      1            // playbackRate
      Loop:           false        // loop
```

`videoElem.height`が0なところに注目してください。`<video>`要素の横幅が`width`属性で設定してあっても、`height`は指定しないないからです。`<img>`ではアスペクト比から未指定の辺の長さを自動で設定してくれましたが、`<video>`ではそうではないところが注意点です。

そのため、キャンバスサイズの調整にはこれらプロパティは使えません。そこで、代替として`offsetWidth`と`offsetHeight`を使うことになります。これらプロパティは実際に画面上にレンダリングされたときのサイズなので、あれば境界線、パディング、スクロールバーのぶんも含まれ、正確にはフレームサイズと異なることもあります。

ビデオオリジナルのサイズは`videoWidth`と`videoHeight`プロパティに主要されています。キャンバスサイズを`width`あるいは`height`をもとに計算するときは、これらから得られるアスペクト比を用います。

時間長を示す`duration`と現在時刻の`currentTime`の単位は秒で、浮動小数点数です。メタデータにはビデオの総フレーム数やフレームレート（秒間に再生するフレームの枚数）がたいていは備わっていますが、HTML5では取得できません（オリジナルのOpenCVではできますが、OpenCV.jsはサポートしていません）。

`volume`は音量で0.0から1.0の浮動小数点数です。0.0が無音、1.0が最大を示します。デフォルトは1.0です。このプロパティには対応するHTML属性がないので、`<video>`要素で音量を指定するときは、次のようにイベントリスナーを介してオブジェクトプロパティから設定します。

```html
<video id="videoTag" src="samples/cat.mp4" onloadedmetadata="this.volume=0.4;">
```

`playbackRate`は再生速度で1.0が通常スピードです。2.0なら倍速、負の値にすれば逆方向に進みます。これも対応するHTML属性はありません。

`loop`は同名のHTML属性と同じで、オートリ―ピートをかけるか否かを真偽値で指定します。デフォルトは`false`です。

#### ビデオキャプチャ

続いて、再生中のビデオフレームをキャプチャしてキャンバスに表示します。キャプチャ画面にはフレーム番号と時間を埋め込みます。

実行例の画面は次の通りです。

<img src="Images/Ch01/html-video-2.png">

コードは次の通りです（ファイル名は`html-video2.html`）。

```html
[File] html-video2.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6  </head>
  7  <body>
  8
  9  <h1>ビデオキャプチャ</h1>
 10
 11  <div>
 12    <video id="videoTag" width="480" autoplay muted src="samples/cat.mp4"></video>
 13    <canvas id="canvasTag" class="placeholder"></canvas>
 14  </div>
 15  <div>
 16    <input type="button" value="Snap!" class="click" onclick="showImage();"/>
 17  </div>
 18
 19  <script>
 20    let videoElem = document.getElementById('videoTag');
 21    let canvasElem = document.getElementById('canvasTag');
 22    let ctx = canvasElem.getContext('2d');
 23
 24    function showImage() {
 25      canvasElem.width = videoElem.offsetWidth;
 26      canvasElem.height = videoElem.offsetHeight;
 27      ctx.drawImage(videoElem, 0, 0, videoElem.offsetWidth, videoElem.offsetHeight);
 28
 29      let quality = videoElem.getVideoPlaybackQuality();
 30      let frameNumber = quality.totalVideoFrames;
 31      let currentTime = videoElem.currentTime;
 32      ctx.font = '16px sans-serif';
 33      ctx.fillText(`Snapped at ${frameNumber} ${currentTime}`, 10, 30);
 34    }
 35
 36    videoElem.addEventListener('loadeddata', showImage);
 37  </script>
 38
 39  </body>
 40  </html>
```

基本構成はこれまでと変わりません。

加わったのは、キャプチャを指示するボタン（16行目）、貼り付け先のキャンバスとそのコンテクスト（13、21～22行目）、そしてキャンバスサイズを現在の`<video>`と同じにするためのプロパティ設定（25～26行目）です。12行目のHTML要素で指定していない`height`は0なので、`offsetWidth`と`offsetHeight`プロパティを使います。0のままでもエラーにはなりませんが、キャプチャ画像は高さ0では見えません（ただし枠線は見えます）。

フレーム番号と現在時刻は、描画コンテクストのメソッド`fillText()`から描き込みます（32～33行目）。

```javascript
 32      ctx.font = '16px sans-serif';
 33      ctx.fillText(`Snapped at ${frameNumber} ${currentTime}`, 10, 30);
```

描画に先立ち、`font`プロパティからコンテクストにフォントを設定します（32行目）。代入する文字列はCSSの`font`と同じ設定文字列です。

続いて、そのフォントで文字列を描画します（33行目）。メソッドの第1引数が描く文字列、第2、第3引数がそのキャンバス上で位置座標です。デフォルトでは文字列左下がこの位置に重ねられます。したがって、第3引数にはフォントの高さぶんのスペースを加味した位置を指定します。

描画コンテクストにはこれ以外にも多様なプロパティやメソッドが用意されており、絵を描いたり、アニメーションを生成したりすることもできます。一例として、[1.5節](#15-カメラを操作する "INTERNAL")では文字列を描いた画像を生成し、[1.8節](01-2-html5.md#18-ユーザ操作を制御する "INTERNAL")ではマウスによるく部分領域の選択時の枠線を描画します。

なお、OpenCVの文字列描画機能はフォントの都合で英文字だけに対応しています。日本語文字列を描くのなら、HTML5の機能を使わなければなりません。この方法は[1.7節](01-2-html5.md#17-日本語文字を描画する "INTERNAL")で取り上げます。

#### 品質メトリックス

現在表示されているフレームの番号は、品質メトリックスを管理する`VideoPlaybackQuality`オブジェクトから取得します。

このオブジェクトは`HTMLVideoElement.getVideoPlaybackQuality()`から得られます（29行目）。そして、フレーム番号はその`totalVideoFrames`プロパティから取得できます（30行目）。

```javascript
 29      let quality = videoElem.getVideoPlaybackQuality();
 30      let frameNumber = quality.totalVideoFrames;
 ︙
 33      ctx.fillText(`Snapped at ${frameNumber} ${currentTime}`, 10, 30);
```

その名が示すように、このプロパティは「これまでに得られたフレームの数」を収容しています。再生性能の都合などでフレーム落ちがあればそのぶんは含まれないので、厳密には「フレーム番号」ではありません。また、リピート再生をしていれば全フレーム数の何倍ものフレーム数が報告されますし、スライダで途中を飛ばせばそのぶんはなかったことになります。つまり、参考程度で、フレームに依拠したスクリプティング（たとえば、必ず10フレーム単位にキャプチャする）には利用できません。また、この機能をサポートしてないブラウザもあります。

31行目で得ている現在時間のほうがより正確なので、フレーム位置を特定したいときはそちらを用います。

```javascript
 31      let currentTime = videoElem.currentTime;
```



### 1.3 字幕を加える

#### 字幕（テキストトラック）

ビデオには`<track`>要素から字幕を加えることができます。HTMLの仕様はビデオ（あるいはオーディオ）の特定の時間範囲内に付随するデータ全般をテキストトラックと総称しますが、ここでは字幕と呼びます。

本節では`<track>`の基本的な用法を示し、次いで字幕ファイル（WebVTTファイル）の作成方法を説明します。そのうえで、スクリプトから`<track>`オブジェクトの字幕テキストを抽出する方法を示します。

#### track要素

まずは`<track>`の用法です。次に実行画面を示します。

<img src="Images/Ch01/html-caption-1.png">

> 注意：字幕ファイルをローカル（`file:///...`）から読み込むと、クロスサイトリソース共有（CORS）制約に抵触し、エラーが上がります。CORSについては[第2章](TBA "INTERNAL")で説明します。

字幕は（とくに設定がなければ）自動で配置されます。上の画面では操作パネルが表示されているのでその上に描画されますが、パネルがなければ画面下端に置かれます。

コードを次に示します（ファイル名は`html-caption1.html`）。

```html
[File] html-caption1.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6    <script async src="libs/opencv.js" type="text/javascript"></script>
  7  </head>
  8  <body>
  9
 10  <h1>字幕付きビデオ</h1>
 11
 12  <div>
 13    <video id="videoTag" width="480" controls autoplay muted>
 14      <source src="samples/cat.mp4" type="video/mp4"/>
 15      <track id="trackTag" kind="captions" srclang="ja" default
 16        src="samples/cat.vtt"/>
 17    </video>
 18  </div>
 19
 20  </body>
 21  </html>
```

字幕データファイルを指定しているのが、`<video></video>`要素の間に挟まれた`<track>`要素です（15行目）。

```html
 13    <video id="videoTag" width="480" controls autoplay muted>
 14      <source src="samples/cat.mp4" type="video/mp4"/>
 15      <track id="trackTag" kind="captions" srclang="ja" default
 16        src="samples/cat.vtt"/>
 17    </video>
```

英日独仏など各国語の字幕に対応できるよう、`<track>`は複数挟むことができます。`default`属性は、その中でもどれをデフォルトに用いるかを指定するものです。上記のコードでは1つしかないので不必要な気もしますが、`default`指定がなければ、操作パネルから能動的に選択しなければ字幕は表示されません。

`kind`は字幕の種類を示します。たとえば、テキストデータが字幕（subtitiles）なのか、クローズドキャプション（captions）なのかを示します。たいていはcaptionsを指定すれば問題はありません。指定可能なキーワードは現在5種類が定義されているので、詳しいことはMDNの`<track>`の説明を参照してください。

`srclang`はテキストデータの言語を示します。これを「言語タグ」といいます。`kind`にsubtitlesキーワードを指定したときには、必須の属性です。使用できる言語タグはインターネット標準のRFC 5646で定義されており、次のIANA（インターネットの標準化機構）のURLから全リストをチェックできます。

```https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry```

付け足しですが、ここでは[1.2節](#12-ビデオを表示する "INTERNAL")で軽く触れた`<source>`を用いています。実用上意味があるわけではなく、参考までです。

#### WebVTTファイル

字幕データはWebVTT（Web Video Text Track）と呼ばれるフォーマットで別ファイルに記述します。仕様は、W3Cのワーキンググループが開発中の「WebVTT: The Web Video Text Tracks Format」で規定されています。URLを次に示します。

```https://www.w3.org/TR/webvtt1/```

ファイルはメモ帳などで作成できるテキスト形式で、文字エンコーディングにはUTF-8を用います。

ここで使用したファイル（`samples/cat.vtt`）を次に示します（行番号はファイルには含まれません）。

```
[File] cat.vtt
  1  WEBVTT - 白黒ぶち猫
  2
  3
  4  00:00.000 --> 00:03.500
  5  あ、まんまくれるのかにゃ。
  6
  7  00:04.000 --> 00:08.999
  8  なんだ、くれないんだ。
  9  じゃ、いいや。
```

ファイル先頭には文字列でWEBVTTと示します。同じ行に、スペースを挟んで好みの文字を書き込んでもよいので、たいていは中身を短く説明する文を入れます。

先頭行から2つ以上空行を入れます。WebVTTの改行はLF（`0A`）だけ、CR（`0D`）だけ、CRLF（`0D0A`）のいずれでもよいことになっていますが、CRLFがよいでしょう。

字幕を出すタイミングとその文章のかたまりを、仕様ではキュー（cue）と呼びます。キューの間には空行を1つ以上入れます。上記ではくキューは2つあります。

キューの先頭は表示タイミングで、時:分:秒.ミリ秒で記述します（仕様ではcue timingと呼びます）。上記の例のように、時は0なら省いてもかまいません。表示タイミングは開始と終了からなり、その間にはスペースと「-->」（ハイフン2つと大なり記号）とスペースを挟みます。

表示タイミングに続けて、表示する文を書きます（cue payload）。複数行でもかまいません。

表示タイミングは必ずしも連続している必要はありません。上記の例では、最初のキューは3.5秒のタイミングで消え、次は4.0秒で登場します。3.5～4.0の間は字幕が表示されないだけです。

#### 字幕の操作

字幕データはJavaScriptから操作できます。動作状況を次の画面から示します。

<img src="Images/Ch01/html-caption-2.png">

コンソールには、字幕が表示された時刻とその文字列が表示されます。3.5秒時点から0.5秒間は字幕がないので、その旨示されています。

コードを次に示します（ファイル名は`html-caption2.html`）。

```html
[File] html-caption2.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6    <script async src="libs/opencv.js" type="text/javascript"></script>
  7  <body>
  8
  9  <h1>字幕付きビデオ（字幕操作）</h1>
 10
 11  <div>
 12    <video id="videoTag" width="480" controls>
 13      <source src="samples/cat.mp4" type="video/mp4"/>
 14      <track id="trackTag" kind="captions" srclang="ja" default src="samples/cat.vtt"/>
 15    </video>
 16  </div>
 17
 18  <script>
 19    let videoElem = document.getElementById('videoTag');
 20    let trackElem = document.getElementById('trackTag');
 21
 22    function showCue(evt) {
 23      let cueList = evt.target.track.activeCues;
 24      if (cueList.length > 0)
 25        console.log(`${videoElem.currentTime} ${cueList[0].text}`);
 26      else
 27        console.log(`${videoElem.currentTime} Cue changed but no cue`);
 28    }
 29
 30    trackElem.addEventListener('cuechange', showCue);
 31  </script>
 32
 33  </body>
 34  </html>
```

#### HTMLTrackElementオブジェクトと字幕情報

字幕情報は、`<track>`オブジェクトの`HTMLTrackElement`（20行目）から操作します。

```javascript
20    let trackElem = document.getElementById('trackTag');
```

このオブジェクトにはHTML要素の一般的なイベントに加え、`cuechange`というイベントが用意されています。その名の通り、字幕に変更があったときに上がってくるものなので、字幕が表示されたときだけでなく、消えたときにも発生します。実行例で無字幕状態になった3.5秒時点がこれに該当します。

本コードでは、処理メソッド`showCue()`（22～28行目）を登録しています（30行目）。

```javascript
 22    function showCue(evt) {
 23      let cueList = evt.target.track.activeCues;
 24      if (cueList.length > 0)
 25        console.log(`${videoElem.currentTime} ${cueList[0].text}`);
 26      else
 27        console.log(`${videoElem.currentTime} Cue changed but no cue`);
 28    }
 29
 30    trackElem.addEventListener('cuechange', showCue);
```

字幕情報は`HTMLTrackElement`の`track`プロパティに収容されています。31行目の変数を使えば`trackElem.track`ですが、ここは処理メソッドが上がってきたイベントオブジェクト（22行目の`evt`）からアクセスするので`evt.target.track`と書いています（23行目）。

`HTMLTrackElement.track`は`TextTrack`というオブジェクトです。この中には`activeCues`という、現在使用中のキューを収容したプロパティが用意されています。複数形であることからわかるように、これは配列のような列挙型オブジェクトです（`TextTrackList`）。23行目では、これをいったん変数`cueList`に格納しています。

その時点で字幕が表示されていれば、そこに複数のキューが収容されています。その数は`length`から知ることができます（24行目）。字幕が表示されていなければ、この値は0です。

ここではキューは1つしかないので、`TextTrackList`の0番目の要素にアクセスします（25行目の`cueList[0]`）。これは`TextTrackCue`というオブジェクトで、その中には（いろいろありますが）`text`という字幕文字列を収容したプロパティがあります。25行目で表示しているのはこれです。

`HTMLTrackElement`から字幕文字列（`string`）に至るには、いくつものオブジェクトを経由しなければなりません。次図に模式的にオブジェクトの連携を示します。

<!-- 847x275 -->
<img src="Images/Ch01/html-caption-objects.png" width="500">



### 1.4 いろいろなビデオ操作

#### ビデオアプリケーション

[1.2節](#12-ビデオを表示する "INTERNAL")で説明した方法でビデオのフレームや情報を取得、あるいはセットすることができれば、ビデオを操作するいろいろなアプリケーションを作成できます。

ここでは次の2つのアプリケーションを紹介します。

- ビデオシャッフリング ... フレームをランダムに行き来します。音楽トラックをランダムに選択するシャッフリングと考え方は同じで、フレーム単位でそれが行われます。
- ビデオサムネール ... 一定間隔でフレームを抽出し、それらを並べた画像を生成することで、ビデオ全体を一覧できるようにします。

#### ビデオシャッフリング

ビデオプロパティのひとつに、現在時刻を示す`currentTime`があります。このプロパティは読み書きのどちらもサポートしているので、値を書き込めば、その位置にビデオがジャンプします。この時間操作を繰り返し行うのが、ビデオを行ったり来たりするシャッフリングです。

ここでは、ビデオ画面上で<kbd>ALT</kbd>キーを押下しながらマウスクリックしたら、ランダムな位置に飛ぶスクリプトを書きます。

コードは次の通りです（ファイル名は`html-shuffle.html`）。

```html
[File] html-shuffle.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6  </head>
  7  <body>
  8
  9  <h1>ビデオ ランダムシャッフリング</h1>
 10
 11  <p>ビデオ上で <kbd>ALT</kbd> キーを押しながらマウスクリックすれば、ランダムにシークします</p>
 12
 13  <div>
 14    <video id="videoTag" width="480" src="samples/cat.mp4"></video>
 15  </div>
 16
 17  <script>
 18    let videoElem = document.getElementById('videoTag');
 19
 20    function ready() {
 21      videoElem.controls = false;
 22      videoElem.loop = true;
 23      videoElem.muted = true;
 24      videoElem.play();
 25    }
 26
 27    function seeked() {
 28      console.log(`Seeked to ${videoElem.currentTime}`);
 29    }
 30
 31    function clicked(evt) {
 32      if (evt.altKey === true) {
 33        let nextPos = videoElem.duration * Math.random();
 34        videoElem.currentTime = nextPos;
 35      }
 36    }
 37
 38    videoElem.addEventListener('loadeddata', ready);
 39    videoElem.addEventListener('click', clicked);
 40    videoElem.addEventListener('seeked', seeked);
 41  </script>
 42
 43  </body>
 44  </html>
```

特定のイベントに結び付けられたメソッドが3つ用意してあります。

`ready()`メソッド（20～25行目）はビデオが準備できたとき、つまり`loadeddata`イベントが発生したとき（38行目）にビデオの各種設定をします。

```javascript
 20    function ready() {
 21      videoElem.controls = false;
 22      videoElem.loop = true;
 23      videoElem.muted = true;
 24      videoElem.play();
 25    }
 ︙
 38    videoElem.addEventListener('loadeddata', ready);
```

21～23行目はいずれも、対応する`HTML`属性からも設定ができますが、ここではスクリプトから設定しています。24行目の`play()`メソッドは再生を開始する命令で、`autoplay`属性に相当します。

`clicked()`メソッド（31～36行目）はビデオ部分がマウスクリックされたとき、つまり`click`イベントが発生したときに（39行目）、`currentTime`プロパティをランダムに変更します。

```javascript
 31    function clicked(evt) {
 32      if (evt.altKey === true) {
 33        let nextPos = videoElem.duration * Math.random();
 34        videoElem.currentTime = nextPos;
 35      }
 36    }
 39    videoElem.addEventListener('click', clicked);
```

<kbd>ALT</kbd>キーが押下されているときのみシャッフルするので、上がってきたイベント`evt`（31行目）の`altKey`プロパティをチェックします（32行目）。フラグが立っていれば、`HTMLVideoElement.currentTime`を先頭から末尾（`duration`）までのランダムな位置に変更します（33～34行目）。

`seeked()`メソッド（27～29行目）はビデオでシーク（移動）が発生したとき（`seeked`イベント）に、コンソールに新しい位置を表示するためのものです。

紙面ではフレームがジャンプするところを再現できないので、実行画面は割愛し、`seeked()`が出力するコンソールメッセージを次に示します。

```
Seeked to 2.916887             // 開始後、ALT-click
Seeked to 0.00032              // 末尾からオートリピートで先頭に戻った
Seeked to 5.787036             // 再びALT-Click
```

#### ビデオサムネール

サムネールは、縮小した見本画像を並べた画像です。親指の爪（thumbのnail）サイズだから、サムネールです。ネガフィルム（銀塩）写真の時代にはべた焼き、あるいはコンタクトシートと呼ばれました。

サムネールの利点は高い一覧性です。欠点は、小さくし過ぎると画像を認識できなくなることです。では大きくすればよいかというと、それに伴って台紙も大きくなるので、数が多いとディスプレイに収まらなくなり、逆に一覧性が低下します。

ここでは、ビデオから一定間隔で抜き出したフレームを、プレーンなキャンバスに縮小して格子状に張り付けることで作成します。次に、サンプルの画面を示します。

<img src="Images/Ch01/html-thumbnail.png">

コードを次に示します（ファイル名は`html-thumbnail.html`）。

```html
[File] html-thumbnail.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6  </head>
  7  <body>
  8
  9  <h1>ビデオ サムネール</h1>
 10
 11  <div>
 12    <video id="videoTag" width="480" src="samples/cat.mp4"></video>
 13    <canvas id="canvasTag" class="placeholder"></canvas>
 14  </div>
 15
 16  <script>
 17    let sheetSize = {width: 4, height: 3};
 18    let imgWidth = 128;
 19    let imgHeight = undefined;
 20    let count = 0;
 21    let timeSeries = undefined;
 22
 23    let videoElem = document.getElementById('videoTag');
 24    let canvasElem = document.getElementById('canvasTag');
 25    let ctx = canvasElem.getContext('2d');
 26
 27    function prepare() {
 28      let aspect = videoElem.videoHeight / videoElem.videoWidth;
 29      imgHeight = Math.floor(imgWidth * aspect);
 30      canvasElem.width = imgWidth * sheetSize.width;
 31      canvasElem.height = imgHeight * sheetSize.height;
 32
 33      let number = sheetSize.width * sheetSize.height;
 34      let interval = videoElem.duration / number;
 35      timeSeries = [...Array(number).keys()].map(i => i * interval);
 36
 37      videoElem.muted = true;
 38      videoElem.play();
 39    }
 40
 41    function pasteFrame() {
 42      let pos_x = (count % sheetSize.width) * imgWidth;
 43      let pos_y = Math.floor(count / sheetSize.width) * imgHeight;
 44      ctx.drawImage(videoElem, pos_x, pos_y, imgWidth, imgHeight);
 45    }
 46
 47    function timeUpdated() {
 48      if (videoElem.currentTime > timeSeries[count]) {
 49        console.log(`${count} at ${videoElem.currentTime}`);
 50        pasteFrame();
 51        count ++;
 52      }
 53    }
 54
 55    videoElem.addEventListener('loadeddata', prepare);
 56    videoElem.addEventListener('timeupdate', timeUpdated);
 57  </script>
 58
 59  </body>
 60  </html>
```

27～39行目の`prepare()`メソッドは初期設定をするもので、ビデオの最初のフレームが用意できたときに呼び出します。

```javascript
 27    function prepare() {
 ︙
 39    }
 ︙
 55    videoElem.addEventListener('loadeddata', prepare);
```

メソッドは、サムネールの枚数ぶんのスペースを持ったキャンバスを用意します。サムネールはキャンバスに格子状に配置するので、縦横の格子の数と格子の横幅を先に決めます。

```javascript
 17    let sheetSize = {width: 4, height: 3};
 18    let imgWidth = 128;
```

これでキャンバスのレイアウトが次の図のように決まりました。

<!-- 888x387 -->
<img src="Images/Ch01/html-thumbnail-layout.png" width="500">

各格子の左上の数値がサムネールの番号です。中央の括弧の数値は格子の横縦の位置を示しており、横はサムネール番号を横の格子数（4）で割った時の余りから、縦は同じく番号を横の格子数で割って小数点以下を切り捨てることで得られます（図右の計算式）。格子位置からキャンバス上の座標位置を計算するには、それぞれ格子のサイズを掛けるだけです。たとえば、図にあるように格子(2, 1)は(128×2, 36×1)なので(256,72)です。

格子の横幅は指定していますが、高さは未指定です。これは、ビデオサイズから得られるアスペクト比から計算します（28～29行目）。

<!-- canvas.width に float を代入すると、自動的に int に変換される。でも、この場合は sheetSize を掛けると丸め誤差は出るので、先に int にしたほうがよい。-->
```javascript
 28      let aspect = videoElem.videoHeight / videoElem.videoWidth;
 29      imgHeight = Math.floor(imgWidth * aspect);
```

キャンバスのサイズは格子サイズと格子レイアウトから決定します（30～31行目）。

```javascript
 30      canvasElem.width = imgWidth * sheetSize.width;
 31      canvasElem.height = imgHeight * sheetSize.height;
```

続いて、フレームを取り出すタイミングを決めます（20～21、33～35行目）。

```javascript
 21    let timeSeries = undefined;
 ︙
 33      let number = sheetSize.width * sheetSize.height;
 34      let interval = videoElem.duration / number;
 35      timeSeries = [...Array(number).keys()].map(i => i * interval);
```

ビデオの時間長を格子数で割ることで取り込み間隔を計算します（33～34行目）。サンプルで用いているビデオの時間長は9.2秒なので、12で割ると0.77秒間が得られます。次いで、0からスタートしてこの間隔の秒位置の配列を作成します（35行目）。ぱっと見にはわかりにくいですが、`Array`コンストラクタで12要素の配列を作成し（`Array(number)`）、そのインデックス番号からなる配列を生成し（`.keys()`。これで[0, 1, ..., 11]が得られる）、すべての要素に間隔の0.77を掛けている（`map(i => i * interval)`）だけです。

`prepare()`メソッドは最後に、ビデオオーディオをミュートにし（37行目）、再生を開始させています（38行目）。

```javascript
 37      videoElem.muted = true;
 38      videoElem.play();
```

一定間隔でフレームの取り出しを行うには、`timeupdate`イベントが便利です。これを登録しているのが56行目です。

```javascript
 56    videoElem.addEventListener('timeupdate', timeUpdated);
```

このイベントは`HTMLVideoElement.currentTime`が更新されると発生することになっていますが、実際の発火はフレーム切り替えよりもずっと遅いタイミングです。MDNは15～250ミリ秒くらいに1回と述べています。一般的なビデオのフレームレートは30 fps（33ミリ秒）です。ここでは0.77秒に1回サムネール取り込みますが、このテンポだと、遅いときには取り込みの間に3回くらいしか発火しません。


`timeupdate`イベント発火で呼び出される`timeUpdated()`メソッドは47～53行目で定義しています。

```javascript
 20    let count = 0;
 ︙
 47    function timeUpdated() {
 48      if (videoElem.currentTime > timeSeries[count]) {
 49        console.log(`${count} at ${videoElem.currentTime}`);
 50        pasteFrame();
 51        count ++;
 52      }
 53    }
```

現在時刻が`timeSeries`の`count`番目の要素よりも大きければ、取り込みです（48行目）。取り込んだら、格子番号を記録している`count`（20行目で0にセット）を1つ繰り上げます（51行目）。

50行目で呼び出している`pasteFrame()`メソッド（41～45行目）がキャンバスにフレームを貼り付けます。

```javascript
 41    function pasteFrame() {
 42      let pos_x = (count % sheetSize.width) * imgWidth;
 43      let pos_y = Math.floor(count / sheetSize.width) * imgHeight;
 44      ctx.drawImage(videoElem, pos_x, pos_y, imgWidth, imgHeight);
 45    }
```

格子番号の`count`から格子位置、そこからキャンバス上の位置を決定する方法は、先ほど図から示しました。`drawImage()`はその位置に格子サイズで貼り付けるので、もとのフレームは縮小コピーされます（[1.1節](#11-画像を表示する "INTERNAL")参照）。



### 1.5 カメラを操作する

#### カメラはビデオと同じ

カメラ映像でも、HTML要素には`<video>`を使います。DOM上のオブジェクトも`HTMLVideoElement`で、そこからフレームをコピーするのに`drawImage()`を使うのも同じです。

ただし、カメラデバイスを取得し、そこから得られるビデオストリームを`<video>`に割り当てるという追加作業が必要です。外部機器のカメラはブラウザに備わったオブジェクトなので、取得には`navigator`に用意された`mediaDevices.getUserMedia()`メソッドを使います。

本節では、カメラのベーシックな用法を説明します。また、使用を終えたカメラの解放方法も示します。明示的にカメラオフにしなければ、他のアプリケーションがカメラを利用できなくなるからです。

`<video>`には、カメラがオフになっているときに表示する「ポスター」画像を設定できます。ここではポスター画像をHTML5のグラフィックス作成機能から生成します。

#### カメラのオンオフ

まずは基本動作コードの動作状況を次の画面から示します。初期状態ではカメラが取得されていないので`<video>`はまっくろで、サイズもデフォルトの300×150のままです。

<img src="Images/Ch01/html-camera-1.png">

`<input type="button">`で生成した左下の［起動］ボタンをクリックすると、カメラ映像が表示されます。ボタン上の文字列も［停止］に変わります。

<img src="Images/Ch01/html-camera-2.png">

［停止］をクリックすると、カメラが解放されます。

コードは次の通りです（ファイル名は`html-camera1.html`）。

```html
[File] html-camera1.html
  1  <!DOCTYPE html>
  2  <html lang="ja-JP">
  3  <head>
  4    <meta charset="UTF-8">
  5    <link rel=stylesheet type="text/css" href="style.css">
  6  </head>
  7  <body>
  8
  9  <h1>カメラのオンオフ</h1>
 10
 11  <div>
 12    <video id="videoTag" controls muted></video>
 13  </div>
 14  <div>
 15    <input type="button" id="buttonTag" value="起動" class="click"/>
 16  </div>
 17
 18  <script>
 19    let cameraSettings = {
 20      audio: false,
 21      video: {
 22        width: 480,
 23        height: 360,
 24        facingMode: 'environment'
 25      }
 26    };
 27    let cameraState = 0;                             // 0=停止中 1=起動中
 28    let opString = ['起動', '停止'];
 29
 30    let videoElem = document.getElementById('videoTag');
 31    let buttonElem = document.getElementById('buttonTag');
 32
 33    function cameraStart() {
 34      navigator.mediaDevices.getUserMedia(cameraSettings)
 35      .then(function(mediaStream) {
 36        videoElem.srcObject = mediaStream;
 37        videoElem.play();
 38      });
 39    }
 40
 41    function cameraStop() {
 42      videoElem.pause();
 43      let tracks = videoElem.srcObject.getVideoTracks();
 44      tracks.forEach(function(track) {
 45        track.stop();
 46      });
 47      videoElem.srcObj = undefined;
 48    }
 49
 50    function startStop() {
 51      [cameraStart, cameraStop][cameraState]();
 52      cameraState = 1 - cameraState;
 53      buttonElem.value = opString[cameraState];
 54    }
 55
 56    buttonElem.addEventListener('click', startStop);
 57    videoElem.addEventListener('loadeddata', function(){
 58        console.log(`Camera sizes:
 59          width, height:       ${videoElem.width}x${videoElem.height}
 60          offsetWidth, Height: ${videoElem.offsetWidth}x${videoElem.offsetHeight}
 61          videoWidth, Height:  ${videoElem.videoWidth}x${videoElem.videoHeight}`);
 62    });
 63  </script>
 64
 65  </body>
 66  </html>
```

#### カメラ設定

カメラ取得の処理は`cameraStart()`メソッド（33～39行目）とカメラ設定を収容したオブジェクト（19～26行目）からなっています。先に、設定の説明をします。

```javascript
 19    let cameraSettings = {
 20      audio: false,
 21      video: {
 22        width: 480,
 23        height: 360,
 24        facingMode: 'environment'
 25      }
 26    };
```

オブジェクトには`audio`と`video`のキーがあり、真偽値からそれらを使用するかを指示します。ここではオーディオはオフ（20行目）です。

ビデオはオンですが、`true`の代わりに詳細設定オブジェクトを指定できます（21～25行目）。この内側オブジェクトのキーはいろいろありますが、よく使うのはカメラサイズを指定する`width`と`height`です。単位はピクセルです。

`facingMode`（24行目）は、カメラがフロントとリアのどちらにもある携帯電話などでどちら向きを用いるかを指示するものです。ここで用いているenvironmentはリア側（ディスプレイの反対側）です。フロント側（セルフィ側）にするならuserです。PC内蔵カメラのようにひとつしかなければ、どちらを指定してもそれが選択されます。

#### カメラ取得

カメラの取得は、ブラウザ（ユーザエージェント）そのものを指し示す`navigator`グローバルオブジェクトに収容されている`mediaDevices`プロパティから行います（34行目）。

```javascript
 30    let videoElem = document.getElementById('videoTag');
 ︙
 33    function cameraStart() {
 34      navigator.mediaDevices.getUserMedia(cameraSettings)
 35      .then(function(mediaStream) {
 36        videoElem.srcObject = mediaStream;
 37        videoElem.play();
 38      });
 39    }
```

このプロパティは`MediaDevices`というオブジェクトで、多様なメディアデバイスに対応するように設計されています。カメラを取得するなら、その`getUserMedia()`メソッドを呼び出します（34行目）。引数には、上記で用意したカメラ設定オブジェクトを指定します。

このメソッドは`Promise`を返します。この`Promise`は解決されると（35行目の`then`）、`MediaStream`というカメラのビデオストリームを示すオブジェクトを返します（35行目の無名関数`function()`の引数の`mediaStream`）。`Promise`なので、処理は非同期的です。`Promise`の用法に不慣れな方は、次の「プロミスの使用」と題されたMDNのJavaScriptガイドを参照してください。

```https://developer.mozilla.org/ja/docs/Web/JavaScript/Guide/Using_promises```

`MediaStream`オブジェクトが得られたら、`HTMLVideoElement`（30行目）の`srcObject`プロパティにこれを代入します（36行目）。`src`ではありません。`src`は`<video src=>`から指定されるURL文字列で、`srcObject`はメディアソースを表現するオブジェクトです。ただし、このオブジェクトを「完全」にサポートしているのはSafariだけで、他は「部分的」にしかサポートしていません。本書の利用範囲は問題はありませんでしたが、映像が表示されないなら次の行と入れ替えます。

```javascript
 36        videoElem.src = window.URL.createObjectURL(mediaStream);
```

これで、カメラ映像が`<video>`に結び付けられました。あとは、`HTMLVideoElement.play()`メソッドで再生を開始するだけです（37行目）。`<video>`に`autoplay`属性がセットされていれば不要で、自動で再生を開始します。

#### カメラが使えない

カメラは、別のアプリケーションが使用中ならば利用できません。その場合、`getUserMedia()`は`Promise`の解決に失敗し、次のようにエラーメッセージを表示します。

```
Uncaught (in promise) DOMException: Could not start video source
```

使用中のカメラをオフにし、再度試してください。

カメラを使用しているブラウザは使用中であることをアイコンで明示するので、そこから使用状況はわかります。次にChromeの使用中画面を示します。

<!-- 枠なし版あり -->
<img src="Images/Ch01/camera-inuse-chrome.png">

こちらはFirefoxのものです。

<!-- 枠なし版あり -->
<img src="Images/Ch01/camera-inuse-firefox.png">

カメラ脇のLEDが点灯しているかから確認することができることもあります。

#### カメラの使用許可

ブラウザ（`navigator`）は、（あらかじめ許可しているのでなければ）次の画面のようにカメラの使用許諾を求めます。

<img src="Images/Ch01/camera-request-chrome.png">

許可はOSレベルではアプリケーション単位、アプリケーション（ブラウザ）では宛先（ドメイン＋ポート）単位でコントロールされています。スクリプトがエラー終了するときはそれぞれを確認してください。

Windowsでは［設定］>［プライバシー］>［カメラ］でコントロールします。

Chromeでは右上の［︙］から［設定］>［プライバシーとセキュリティ］>［サイトの設定］>［カメラ］です。Firefoxならこれも右上の［≡］から［設定］>［プライバシーとセキュリティ］の「許可設定」の下の「カメラ」の［設定...］です。ブラウザやそのバージョンによって異なるので、見当たらなかったら検索してください。

#### ビデオ（カメラ）の属性

カメラ映像が用意できると、普通のビデオ同様、`HTMLVideoElement`の`loadeddata`イベントが上がってきます。ここでは、このイベントを契機にビデオサイズを表示させています（57～62行目）。

```javascript
 57    videoElem.addEventListener('loadeddata', function(){
 58        console.log(`Camera sizes:
 59          width, height:       ${videoElem.width}x${videoElem.height}
 60          offsetWidth, Height: ${videoElem.offsetWidth}x${videoElem.offsetHeight}
 61          videoWidth, Height:  ${videoElem.videoWidth}x${videoElem.videoHeight}`);
 62    });
```

出力例を示します。

```
Camera sizes:
        width, height:       0x0
        offsetWidth, Height: 480x360
        videoWidth, Height:  480x360
```

`HTMLVideoElement`プロパティの`width`と`height`がどちらも0であるところに注意してください。

#### カメラの解放

利用が終わったらカメラは解放します。この操作をやっているのが、`cameraStop()`メソッド（41～48行目）です。

```javascript
 41    function cameraStop() {
 42      videoElem.pause();
 43      let tracks = videoElem.srcObject.getVideoTracks();
 44      tracks.forEach(function(track) {
 45        track.stop();
 46      });
 47      videoElem.srcObject = undefined;
 48    }
```

解放操作はいくつかのステップからなっています。

まず、`HTMLVideoElement`の側から、`pause()`メソッドで映像再生を停止します（42行目）。

続いて、映像を構成するトラックを`MediaStream`オブジェクト側から停止します。これが43～46行目です。まず、`MediaStream`の`getVideoTracks()`からトラックオブジェクトの`MediaStreamTrack`配列を取得します（43行目）。映像メディアは複数のトラックを持つこともあるため、戻り値が配列なところが注意点です。次いで、個々の`MediaStreamTrack`を、そのメソッドである`stop()`からトラックを停止します（45行目）。

トラックは通常ひとつだけなので、43～46行目は`videoElem.srcObject.getVideoTracks()[0].stop()`と1行で書いてもたいていは問題ありません。

最後に`videoElem.srcObject`に`undefined`を代入することで無効化します。

停止処理を適切に行わないと、使い終わったと思っていても、他のアプリケーションからはカメラが使えないので注意が必要です。ブラウザがカメラを握って離さなければ、タブを閉じることで強制終了します。

#### 起動・停止のトグル

あとは、ボタンをクリックしたら`cameraStart()`を呼び出し、再度クリックしたら`cameraStop()`を呼び出すトグル操作の実装です（27～31、50～54、56行目）。

```javascript
 27    let cameraState = 0;                             // 0=停止中 1=起動中
 28    let opString = ['起動', '停止'];
 31    let buttonElem = document.getElementById('buttonTag');
 ︙
 50    function startStop() {
 51      [cameraStart, cameraStop][cameraState]();
 52      cameraState = 1 - cameraState;
 53      buttonElem.value = opString[cameraState];
 54    }
 55
 56    buttonElem.addEventListener('click', startStop); 
```

27行目の`cameraState`がカメラのオンオフ状態を管理します。0は停止中（初期状態）、1は再生中を意味します。オンオフなら真偽値を使った方がわかりがよいのですが、数値のほうが配列要素にアクセスしやすいです。状態遷移も、1から現在値を引くだけで0と1が交互に入れ替わるので便利です（52行目）。この状態値はボタン文字列配列（28、53行目）、呼び出しメソッド配列（51行目）を指定するときに使います。

#### SOUND ONLYポスター

`<video>`にはビデオあるいはカメラ映像が再生をスタートするまでの間、つなぎの画像を表示する機能があります。これをポスターフレームといい、次の要領で`poster`属性にポスター画像のURLを指定することで表示します。

```html
<video id="videoTag" controls muted poster="samples/sound-only.png"></video>
```

ここでは、このポスター画像を`<canvas>`のグラフィックス機能から作成します。作成するのは、どことなく某秘密組織がかった定番のこれです。

<img src="Images/Ch01/html-camera-3.png">

コードは、関数化して`libs/seele.js`というファイルに収容しました。次の通りです。

```javascript
[File] libs/seele.js
  7  function soundOnly(w=480, h=360, fontSize=64) {
  8    let canvasElem = document.createElement('canvas');
  9    canvasElem.width = w;
 10    canvasElem.height = h;
 11    let ctx = canvasElem.getContext('2d');
 12
 13    let text = 'SOUND ONLY';
 14    let color = 'rgb(252, 0, 0)';
 15
 16    ctx.fillStyle = 'black';
 17    ctx.fillRect(0, 0, w, h);
 18
 19    ctx.font = `bold ${fontSize}px "Helvetica"`;
 20    ctx.letterSpacing = `-${fontSize/16}px`;
 21    ctx.textBaseline = 'middle';
 22    ctx.textAlign = 'center';
 23    ctx.lineWidth = 3.0;
 24    ctx.strokeStyle = color;
 25    ctx.shadowColor = color;
 26    ctx.shadowBlur = 11;
 27    ctx.strokeText('SOUND ONLY', w/2, h/2);
 28
 29    return canvasElem.toDataURL();
 30  }
```

`createElement()`で作成したDOMオブジェクトは（8行目）、`appendChild()`で親要素の下に配置するのが通例ですが、ここではそれをしていません。グラフィックス描画データを生成するためだけに用意したオブジェクトなので、要素としてドキュメントページに張り付ける必要がないからです。

描画でのポイントは文字色に少しだけ暗めな赤にするところ（14行目）、フォントはヘルベチカの太字にするところ（19行目）、文字の間隔を詰め気味にするところ（20行目）、そして、全体がぼーっと光っているように見せるためぼかしを入れているところです（26行目）。スクリプティングのテクニックとしては、文字列を画像中央に配置できるよう、文字列のベースラインと横位置をどちらも真ん中にしているところがポイントです（21～22行目）。

本物は2語が2段に分けられているとか、フォントは実はマティスだとか、背景のぼかし赤がもっと広いとか、及ばぬところは多々あります。本物は次のURLから得られる公式の「エヴァンゲリオン壁紙」から取得できます。

```https://www.evangelion.co.jp/news/web_screen/```

メソッドは、`HTMLCanvasElement.toDataURL()`メソッドを用いてデータURLを返します（29行目）。これは画像のバイナリデータをBase64でエンコーディングした文字列で、データそのものをHTMLファイルに埋め込むことで、URLの代替として用いることができるものです。ネットワークアクセスなどの都合で画像やデータを同梱したいとき、主として小ぶりなデータで用いられます。URLの代替なので、一般のURL文字列から`src`で指定できます。

メインのコードの根幹は`html-camera1.html`と同じです。異なるのは、この`soundOnly()`の呼び出し結果を`HTMLVideoElement.poster`に代入するところくらいです。次に差分部分だけを示します。完動版のコードは`html-camera2.html`に収録してあります。

```html
[File] html-camera2.html
  6    <script async id="scriptTag" src="libs/seele.js" type="text/javascript">
  7      </script>
 ︙
 58    window.addEventListener('load', function() {
 59      videoElem.poster = soundOnly(
 60        cameraSettings.video.width,cameraSettings.video.height);
 61    });
```

ここでは、`window`がロード完了したタイミングで、`soundOnly()`を呼び出しています。
